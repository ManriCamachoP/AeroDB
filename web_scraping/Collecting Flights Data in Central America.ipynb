{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f509f1e",
   "metadata": {},
   "source": [
    "# Web Scraping for Collecting Airport Data in Central America\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "This Jupyter Notebook aims to collect data on airports in Central America using web scraping techniques. In the context of our graph-oriented database project for airport management, having up-to-date and accurate information about airports in the region is essential.\n",
    "\n",
    "Web scraping will allow us to extract relevant data from online sources, such as aviation authorities' websites and airline sites. This data will include details about geographical locations, airport names, available services, operated routes, and other essential attributes.\n",
    "\n",
    "## Objectives:\n",
    "\n",
    "1. Obtain data on airports in Central America from online sources.\n",
    "2. Extract key information, such as airport names, locations, and operational details.\n",
    "3. Store the collected data in a suitable format for further analysis and use in our graph-oriented database.\n",
    "\n",
    "## Libraries\n",
    "\n",
    "* **Requests**: The requests library allows users to make HTTP requests to the web pages they want to analyze, facilitating the download of HTML content from these pages for further processing.\n",
    "\n",
    "* **Beautiful Soup (bs4)**: Beautiful Soup is a useful tool for parsing and searching HTML elements in the downloaded content. It enables users to search and extract specific information from web pages, such as titles, paragraphs, links, and more.\n",
    "\n",
    "* **Selenium**: When websites use JavaScript to load dynamic content, Selenium becomes a valuable choice. With this library, users can automate a web browser to interact with the website and extract data from pages that require interaction.\n",
    "\n",
    "* **Pandas**: Pandas is an essential library for structuring and manipulating extracted data. It allows users to create DataFrames to organize data into rows and columns, facilitating operations such as cleaning, filtering, and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b51b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import ui\n",
    "import chromedriver_autoinstaller\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf387f",
   "metadata": {},
   "source": [
    "## Web Scraping for Data Collection\n",
    "\n",
    "In this section, we will explore web scraping, an automated technique for extracting data from websites. Key topics include:\n",
    "\n",
    "* **HTTP Requests**: The requests library will be used to download the HTML content of web pages.\n",
    "* **HTML Parsing**: Selenium will be employed to interact with dynamic websites and extract relevant information.\n",
    "* **Data Collection**: The data collection process will be conducted from selected websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6130d792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Can not find chromedriver for currently installed chrome version.\n"
     ]
    }
   ],
   "source": [
    "chromedriver_autoinstaller.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee742d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
